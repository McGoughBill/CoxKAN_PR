{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCGA Genomics\n",
    "\n",
    "Uncomment the experiment you want to run:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_name = \"TCGA-GBMLGG\"\n",
    "# exp_name = \"TCGA-KIRC\"\n",
    "# exp_name = \"TCGA-STAD\"\n",
    "# exp_name = \"TCGA-BRCA\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You shouldn't need to alter any other code."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from lifelines import CoxPHFitter\n",
    "import torchtuples as tt\n",
    "import yaml \n",
    "from lifelines.utils import concordance_index\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "from coxkan import CoxKAN\n",
    "from coxkan.utils import FastCoxLoss, count_parameters, bootstrap_metric, set_seed, SYMBOLIC_LIB"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "SEED = set_seed(42)\n",
    "\n",
    "output_dir = Path('checkpoints') / exp_name\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "cohort = exp_name.split('-')[1]\n",
    "assert cohort in ['BRCA', 'STAD', 'GBMLGG', 'KIRC'], f\"Invalid TCGA cohort: {cohort}\"\n",
    "\n",
    "df_train = pd.read_csv(f'data/TCGA/{cohort}_train.csv', index_col=0)\n",
    "df_test = pd.read_csv(f'data/TCGA/{cohort}_test.csv', index_col=0)\n",
    "\n",
    "duration_col, event_col = 'duration', 'event'\n",
    "covariates = [col for col in df_train.columns if col not in [duration_col, event_col]]\n",
    "print(f'Number of covariates: {len(covariates)}')\n",
    "\n",
    "results = {'CoxPH': {}, 'CoxPH Reg': {}, 'DeepSurv': {}, 'CoxKAN': {}}\n",
    "\n",
    "### Loading configs\n",
    "\n",
    "with open(f'configs/coxkan/{exp_name}.yml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "with open(output_dir / 'config.yml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "with open(f'configs/mlp/{exp_name}.yml', 'r') as f:\n",
    "    mlp_config = yaml.safe_load(f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### Init CoxKAN\n",
    "\n",
    "\n",
    "# if early stopping, split the training data into train and validation sets\n",
    "if config['train_params']['early_stopping'] or mlp_config['early_stopping']:\n",
    "    train, val = train_test_split(df_train, test_size=0.2, random_state=42, stratify=df_train[event_col])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CoxPH and CoxPH with regularization:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# CoxPH without regularization\n",
    "try:\n",
    "    run_coxph = True\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "    def cph_cindex(df):\n",
    "        return cph.score(df, scoring_method='concordance_index')\n",
    "    cindex_train = bootstrap_metric(cph_cindex, df_train, N=100)['formatted']\n",
    "    cindex_test = bootstrap_metric(cph_cindex, df_test, N=100)['formatted']\n",
    "    coxph_str = f'CoxPH - train: {cindex_train}, test: {cindex_test}'; print(coxph_str)\n",
    "    with open(output_dir / 'cindex.txt', 'w') as f:\n",
    "        f.write(coxph_str + '\\n')\n",
    "    results['CoxPH'] = {'train': cindex_train, 'test': cindex_test, 'summary': cph.summary}\n",
    "except Exception as e:\n",
    "    run_coxph = False\n",
    "    print('CoxPH failed:', e)\n",
    "\n",
    "# CoxPH with regularization\n",
    "cph_reg = CoxPHFitter(penalizer=0.5, l1_ratio=1)\n",
    "cph_reg.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "def cph_reg_cindex(df):\n",
    "    return cph_reg.score(df, scoring_method='concordance_index')\n",
    "cindex_train = bootstrap_metric(cph_reg_cindex, df_train, N=100)['formatted']\n",
    "cindex_test = bootstrap_metric(cph_reg_cindex, df_test, N=100)['formatted']\n",
    "coxph_reg_str = f'CoxPH Reg - train: {cindex_train}, test: {cindex_test}'; print(coxph_reg_str)\n",
    "with open(output_dir / 'cindex.txt', 'a') as f:\n",
    "    f.write(coxph_reg_str + '\\n')\n",
    "results['CoxPH Reg'] = {'train': cindex_train, 'test': cindex_test, 'summary': cph_reg.summary}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepSurv:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mlp = tt.practical.MLPVanilla(\n",
    "    in_features=len(covariates), out_features=1, output_bias=False, **mlp_config['init_params']\n",
    ")\n",
    "optimizer = tt.optim.Adam(**mlp_config['optimizer_params'])\n",
    "deepsurv = tt.Model(mlp, loss=FastCoxLoss, optimizer=optimizer)\n",
    "deepsurv_params = count_parameters(mlp)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_test = torch.tensor(df_test[covariates].values).double()\n",
    "y_test = torch.tensor(df_test[[duration_col, event_col]].values).double()\n",
    "\n",
    "def mlp_cindex(df):\n",
    "    lph = deepsurv.predict(torch.tensor(df[covariates].values).double())\n",
    "    return concordance_index(df[duration_col], -lph, df[event_col])\n",
    "\n",
    "def mlp_cindex_metric_fn(lph, labels):\n",
    "    return concordance_index(labels[:, 0].detach().numpy(), -lph.detach().numpy(), labels[:, 1].detach().numpy())\n",
    "\n",
    "# Training\n",
    "if mlp_config['early_stopping']:\n",
    "    X_val = torch.tensor(val[covariates].values).double()\n",
    "    y_val = torch.tensor(val[[duration_col, event_col]].values).double()\n",
    "    X_train = torch.tensor(train[covariates].values).double()\n",
    "    y_train = torch.tensor(train[[duration_col, event_col]].values).double()\n",
    "    log = deepsurv.fit(\n",
    "        X_train, y_train, batch_size=len(X_train), val_data=(X_val, y_val), epochs=mlp_config['epochs'], verbose=False,\n",
    "        metrics={'cindex': mlp_cindex_metric_fn}, callbacks=[tt.callbacks.EarlyStopping(patience=20)]\n",
    "    )\n",
    "else:\n",
    "    X_train = torch.tensor(df_train[covariates].values).double()\n",
    "    y_train = torch.tensor(df_train[[duration_col, event_col]].values).double()\n",
    "    log = deepsurv.fit(\n",
    "        X_train, y_train, batch_size=len(X_train), val_data=(X_test, y_test), epochs=mlp_config['epochs'], verbose=False,\n",
    "        metrics={'cindex': mlp_cindex_metric_fn}\n",
    "    )\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax[0].plot(log.to_pandas()['train_loss'], label='train'); ax[0].plot(log.to_pandas()['val_loss'], label='val')\n",
    "ax[1].plot(log.to_pandas()['train_cindex'], label='train'); ax[1].plot(log.to_pandas()['val_cindex'], label='val')\n",
    "\n",
    "# put a vertical line at the best epoch\n",
    "if mlp_config['early_stopping']:\n",
    "    best_epoch = log.to_pandas().val_cindex.idxmax()\n",
    "    ax[0].axvline(best_epoch, color='k', linestyle='--', label='best model')\n",
    "    ax[1].axvline(best_epoch, color='k', linestyle='--', label='best model')\n",
    "\n",
    "ax[0].legend(); ax[0].set_title('Loss'); ax[1].legend(); ax[1].set_title('C-index')\n",
    "fig.savefig(output_dir / 'mlp_training.png')\n",
    "\n",
    "cindex_train = bootstrap_metric(mlp_cindex, df_train, N=100)['formatted']\n",
    "cindex_test = bootstrap_metric(mlp_cindex, df_test, N=100)['formatted']\n",
    "\n",
    "deepsurv_str = f'DeepSurv - train: {cindex_train}, test: {cindex_test}'; print(deepsurv_str)\n",
    "with open(output_dir / 'cindex.txt', 'a') as f:\n",
    "    f.write(deepsurv_str + '\\n')\n",
    "results['DeepSurv'] = {'train': cindex_train, 'test': cindex_test, 'n_params': deepsurv_params}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "##############\n",
    "### CoxKAN\n",
    "##############\n",
    "ckan = CoxKAN(seed=SEED, **config['init_params'])\n",
    "coxkan_params = count_parameters(ckan)\n",
    "\n",
    "### Training\n",
    "log = ckan.train(df_train, df_test, duration_col, event_col, **config['train_params'],prune_split=0.2)\n",
    "fig = log.plot()\n",
    "fig.savefig(output_dir / 'coxkan_training.png')\n",
    "\n",
    "ckan.cindex(df_test)\n",
    "ckan.plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # Code here to load checkpoint if desired\n",
    "# ckan = CoxKAN(seed=SEED, **config['init_params'])\n",
    "# ckan.load_ckpt(output_dir / 'model.pt')\n",
    "# ckan.cindex(df_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "_ = ckan.predict(df_test)\n",
    "ckan.save_ckpt(output_dir / 'model.pt')\n",
    "\n",
    "cindex_train = bootstrap_metric(ckan.cindex, df_train, N=100)['formatted']\n",
    "cindex_val = bootstrap_metric(ckan.cindex, val, N=100)['formatted'] if config['train_params']['early_stopping'] else None\n",
    "cindex_test = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "\n",
    "ckan_pre_str = f'CoxKAN - train: {cindex_train}, test: {cindex_test}'; print(ckan_pre_str)\n",
    "with open(output_dir / 'cindex.txt', 'a') as f:\n",
    "    f.write(ckan_pre_str + '\\n')\n",
    "results['CoxKAN']['Pre'] = {'train': cindex_train, 'test': cindex_test, 'val': cindex_val, 'n_params': coxkan_params}\n",
    "\n",
    "fig = ckan.plot(beta=10)\n",
    "fig.savefig(output_dir / 'coxkan_pre.png')\n",
    "\n",
    "# save results\n",
    "with open(output_dir / 'results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "    print('Results saved to', output_dir / 'results.pkl')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(For KIRC the pruning search takes ages, but it finds that 0.00263158 is the best threshold - skip it if you want)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### Pruning\n",
    "\n",
    "# If early stopping was used, we have a validation set to select the best pruning threshold\n",
    "if config['train_params']['early_stopping']:\n",
    "    pruning_thresholds = np.linspace(0, 0.05, 20)\n",
    "    pruning_thresholds[0] = config['prune_threshold']\n",
    "    cindices = []\n",
    "    for threshold in pruning_thresholds:\n",
    "        ckan_ = CoxKAN(seed=SEED, **config['init_params'])\n",
    "        ckan_.load_ckpt(output_dir / 'model.pt', verbose=False)\n",
    "        _ = ckan_.predict(df_test)\n",
    "        \n",
    "        prunable = True\n",
    "        for l in range(ckan_.depth):\n",
    "            if not (ckan_.acts_scale[l] > threshold).any():\n",
    "                prunable = False\n",
    "                break\n",
    "        if not prunable:\n",
    "            if threshold == config['prune_threshold']: continue\n",
    "            else: break\n",
    "            \n",
    "        ckan_ = ckan_.prune_nodes(threshold)\n",
    "        _ = ckan_.predict(df_test)\n",
    "\n",
    "        if 0 in ckan_.width: prunable = False\n",
    "        if not prunable:\n",
    "            if threshold == config['prune_threshold']: continue\n",
    "            else: break\n",
    "\n",
    "        ckan_.prune_edges(threshold, verbose=False)\n",
    "        cindices.append(ckan_.cindex(val))\n",
    "        print(f'Pruning threshold: {threshold}, C-Index (Val): {cindices[-1]}')\n",
    "    best_threshold = pruning_thresholds[np.argmax(cindices)]\n",
    "    if np.max(cindices) < 0.51: best_threshold = 0\n",
    "else:\n",
    "    best_threshold = config['prune_threshold']\n",
    "print(f'Best pruning threshold: {best_threshold}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # Code here to load checkpoint if desired\n",
    "# ckan = CoxKAN(seed=SEED, **config['init_params'])\n",
    "# ckan.load_ckpt(output_dir / 'model.pt')\n",
    "# ckan.cindex(df_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results['prune_threshold'] = best_threshold\n",
    "_ = ckan.predict(df_test)\n",
    "ckan = ckan.prune_nodes(best_threshold)\n",
    "_ = ckan.predict(df_test)\n",
    "ckan.prune_edges(best_threshold, verbose=True)\n",
    "_ = ckan.predict(df_test)\n",
    "ckan.cindex(df_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig = ckan.plot(beta=10)\n",
    "fig.savefig(output_dir / 'coxkan_pruned.png')\n",
    "\n",
    "cindex_train = bootstrap_metric(ckan.cindex, df_train, N=100)['formatted']\n",
    "if config['train_params']['early_stopping']: cindex_pruned_val = ckan.cindex(val)\n",
    "else: cindex_pruned_val = None\n",
    "cindex_pruned = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "\n",
    "ckan_pru_str = f'CoxKAN (pruned) - train: {cindex_train}, test: {cindex_pruned}'; print(ckan_pru_str)\n",
    "with open(output_dir / 'cindex.txt', 'a') as f:\n",
    "    f.write(ckan_pru_str + '\\n')\n",
    "results['CoxKAN']['Pruned'] = {'train': cindex_train, 'test': cindex_pruned, 'val': cindex_pruned_val}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolic Fitting"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_unnorm = pd.read_csv(f'./data/TCGA/genomics/{cohort}_genomics.csv', index_col=0)\n",
    "df_test_unnorm = df_unnorm.loc[df_test.index]\n",
    "df_train_unnorm = df_unnorm.loc[df_train.index]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### Symbolic Fitting\n",
    "#\n",
    "# # Initial symbolic fitting (categorical covariates and linear activations)\n",
    "# # ckan.predict(pd.concat([df_train, df_test], axis=0))\n",
    "# ckan.predict(df_test)\n",
    "# for l in range(ckan.depth):\n",
    "#     for i in range(ckan.width[l]):\n",
    "#         for j in range(ckan.width[l+1]):\n",
    "#             if ckan.symbolic_fun[l].funs_name[j][i] != '0':\n",
    "#                 if l == 0 and hasattr(ckan, 'categorical_covariates') and ckan.covariates[i] in ckan.categorical_covariates:\n",
    "#                     ckan.fix_symbolic(l,i,j,'categorical')\n",
    "#                 else:\n",
    "#                     # try linear fit\n",
    "#                     _, _, r2 = ckan.suggest_symbolic(l,i,j,lib=['x'], verbose=False)\n",
    "#                     if r2 > 0.975:\n",
    "#                         ckan.fix_symbolic(l,i,j,'x',verbose=False)\n",
    "#                         print(f'Fixed ({l},{i},{j}) as linear')\n",
    "# ckan.cindex(df_test)\n",
    "\n",
    "_ = ckan.auto_symbolic(verbose=True)\n",
    "_ = ckan.predict(df_test)\n",
    "fig = ckan.plot(beta=10, in_vars=[r'$x_1$', r'$x_2$', r'$x_3$',r'$x_4$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_symbolic.png')\n",
    "cindex_symbolic = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Symbolic: {cindex_symbolic}\")\n",
    "formula = ckan.symbolic_formula()[0][0]\n",
    "formula"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For STAD and GBMLGG, calling `auto_symbolic` after a forward pass on the test set is sufficient for symbolic fitting.\n",
    "\n",
    "For BRCA and KIRC, the heavy outliers cause symbolic fitting to fail so we have to be more careful."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if exp_name == 'TCGA-STAD' or exp_name == 'TCGA-GBMLGG':\n",
    "    lib = list(SYMBOLIC_LIB.keys()).copy()\n",
    "    df_for_fitting = df_test\n",
    "    ckan.predict(df_for_fitting)\n",
    "    ckan.auto_symbolic(min_r2=0, lib=lib, verbose=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For BRCA and KIRC, we see that certain activation functions diverge in regions that were unconstrained during training but are present in the test set. We remove these outlier patients for symbolic fitting."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if exp_name == 'TCGA-BRCA' or exp_name == 'TCGA-KIRC':\n",
    "\n",
    "    # first we visualize all activations that are not pruned or already symbolic\n",
    "    non_symbolic = np.where(ckan.symbolic_fun[0].mask.flatten().numpy() == 0)[0]\n",
    "    # fig, axes = plt.subplots(len(non_symbolic)//3, 3, figsize=(15, 5*len(non_symbolic)//3))\n",
    "    # axes = axes.flatten()\n",
    "    n=0\n",
    "    ckan.predict(df_test)\n",
    "    outlier_acts = []\n",
    "    for j, mask in enumerate(ckan.symbolic_fun[0].mask):\n",
    "        for i in np.where(mask.numpy() == 0)[0]:\n",
    "            l, i, j = 0, i, j\n",
    "\n",
    "            # inputs = ckan.spline_preacts[l][:,j,i] \n",
    "            inputs = df_test_unnorm[ckan.covariates[i]].values\n",
    "            outputs = ckan.spline_postacts[l][:,j,i]\n",
    "\n",
    "            # find outliers in outputs\n",
    "            # z = np.abs((outputs - outputs.mean()) / outputs.std())\n",
    "            # outliers = np.where(z > 9)[0]\n",
    "            outliers_ = np.where(np.abs(outputs) > 1000)[0]\n",
    "\n",
    "            if len(outliers_) > 0:\n",
    "\n",
    "                rank = np.argsort(inputs)\n",
    "                inputs = inputs[rank]\n",
    "                outputs = outputs[rank]\n",
    "\n",
    "                fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "                ax.scatter(inputs, outputs, marker='x', s=15)\n",
    "                ax.plot(inputs, outputs)\n",
    "                ax.set_title(f'{covariates[i]}  (0,{i},{j})')\n",
    "                n+=1\n",
    "\n",
    "                outlier_acts.append((l,i,j))\n",
    "                # ax.set_yticks([])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if exp_name == 'TCGA-BRCA' or exp_name == 'TCGA-KIRC':\n",
    "\n",
    "    df_for_fitting = df_test\n",
    "    ckan.predict(df_for_fitting)\n",
    "    for (l,i,j) in outlier_acts:\n",
    "\n",
    "        outputs = ckan.spline_postacts[l][:,j,i]\n",
    "        outlier_idx = np.where(np.abs(outputs) > 1000)\n",
    "        print(f'{len(outlier_idx)} outliers removed')\n",
    "        df_for_fitting = df_for_fitting.drop(df_for_fitting.index[outlier_idx])\n",
    "        ckan.predict(df_for_fitting)\n",
    "        \n",
    "    lib = list(SYMBOLIC_LIB.keys()).copy()\n",
    "    ckan.auto_symbolic(min_r2=0, lib=lib, verbose=True)\n",
    "\n",
    "    print(ckan.cindex(df_test))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cindex_symbolic = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f'C-Index (Symbolic): {cindex_symbolic}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "formula = ckan.symbolic_formula(floating_digit=4)[0][0]\n",
    "formula"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig = ckan.plot(beta=10)\n",
    "fig.savefig(output_dir / 'coxkan_symbolic.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### Save results\n",
    "try: cindex_train = bootstrap_metric(ckan.cindex, df_train, N=100)['formatted']\n",
    "except: cindex_train = np.nan\n",
    "\n",
    "ckan_sym_str = f'CoxKAN (symbolic) - train: {cindex_train}, test: {cindex_symbolic}'; print(ckan_sym_str)\n",
    "with open(output_dir / 'cindex.txt', 'a') as f:\n",
    "    f.write(ckan_sym_str + '\\n')\n",
    "\n",
    "if 'sigmoid' in str(formula): formula = str(formula)\n",
    "\n",
    "results['CoxKAN']['Symbolic'] = {'train': cindex_train, 'test': cindex_symbolic, 'formula': formula}\n",
    "with open(output_dir / 'results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "# save c-index results to txt file too\n",
    "with open(output_dir / 'cindex.txt', 'w') as f:\n",
    "    if run_coxph: f.write(coxph_str + '\\n')\n",
    "    f.write(coxph_reg_str + '\\n')\n",
    "    f.write(deepsurv_str + '\\n')\n",
    "    f.write(ckan_pre_str + '\\n')\n",
    "    f.write(ckan_pru_str + '\\n')\n",
    "    f.write(ckan_sym_str + '\\n')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we call `symbolic_rank_terms` to get the importance of the terms in terms of the standard deviations of the features over the full dataset. Due to outliers, certain features will have inflated standard deviations which do not correlate with feature importance. For this reason we remove outliers based on z score. \n",
    "\n",
    "Important: Play around with the z_score_threshold and view the activations in the next cell to check you are removing outliers correctly (the appropriate threshold is different for different datasets). You want the z_score to be just low enough to remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "thresh = {\n",
    "    'TCGA-GBMLGG': 2,\n",
    "    'TCGA-STAD': 2.2,\n",
    "    'TCGA-BRCA': 5,\n",
    "    'TCGA-KIRC': 3\n",
    "}\n",
    "\n",
    "if len(ckan.width) <= 3:\n",
    "\n",
    "    fullset = pd.concat([df_train, df_test], axis=0)\n",
    "    ckan.predict(fullset)\n",
    "    terms_std = ckan.symbolic_rank_terms(z_score_threshold=thresh[exp_name])\n",
    "    terms_std = {k: v for k, v in sorted(terms_std.items(), key=lambda item: item[1], reverse=True) if v > -0.00001}\n",
    "    results['CoxKAN']['Symbolic']['terms_std'] = terms_std\n",
    "    with open(output_dir / 'results.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    print(results['CoxKAN']['Symbolic']['terms_std'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cph_reg.summary.sort_values('p', ascending=True).head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def set_red(ax):\n",
    "    # Set the colors for the axes, labels, and tick marks\n",
    "    ax.spines['bottom'].set_color('red')\n",
    "    ax.spines['top'].set_color('red') \n",
    "    ax.spines['right'].set_color('red')\n",
    "    ax.spines['left'].set_color('red')\n",
    "    \n",
    "    ax.title.set_color('red')\n",
    "\n",
    "def format_feature(feature):\n",
    "\n",
    "    if exp_name == 'TCGA-GBMLGG':\n",
    "        if 'rna' in feature:\n",
    "            gene = feature.split('_')[0]\n",
    "            feature_type = 'RNA'\n",
    "            return rf'$\\text{{{gene}}}_{{{feature_type}}}$'\n",
    "        else:\n",
    "            gene = feature \n",
    "            feature_type = 'CNV'\n",
    "            return rf'$\\text{{{gene}}}_{{{feature_type}}}$'\n",
    "    else:\n",
    "        if ' ' in feature:\n",
    "            gene = feature.split(' ')[0]\n",
    "            feature_type = feature.split('_')[1]\n",
    "            if feature_type != 'mut': feature_type = feature_type.upper()\n",
    "            return rf'$\\text{{{gene}}}_{{{feature_type}}}$'\n",
    "        else:\n",
    "            return feature\n",
    "\n",
    "if len(ckan.width) <= 3:\n",
    "\n",
    "    significant_nonlinears = []\n",
    "    for term, std in list(terms_std.items())[:10]:\n",
    "        act = term.split(' ')[0]\n",
    "        l, i, j = [int(x) for x in act[1:-1].split(',')]\n",
    "        if ckan.symbolic_fun[l].funs_name[j][i] != 'x':\n",
    "            significant_nonlinears.append((l,i,j))\n",
    "\n",
    "    n=0\n",
    "    ckan.predict(df_for_fitting)\n",
    "    for act in significant_nonlinears:\n",
    "\n",
    "        l, i, j = act\n",
    "        inputs = ckan.spline_preacts[l][:,j,i]\n",
    "        inputs_unnorm = df_unnorm.loc[df_for_fitting.index][covariates[i]].values\n",
    "        outputs = ckan.spline_postacts[l][:,j,i]\n",
    "        rank = np.argsort(inputs)\n",
    "        inputs = inputs[rank]\n",
    "        inputs_unnorm = inputs_unnorm[rank]\n",
    "        outputs = outputs[rank]\n",
    "\n",
    "        lst = term.split(' ')[1:]\n",
    "        term = ' '.join(lst)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "        ax.scatter(inputs_unnorm, outputs, marker='x', s=30, color='red')\n",
    "        ax.plot(inputs_unnorm, outputs, color='red')\n",
    "\n",
    "        ax.set_xlabel(f'{format_feature(covariates[i])}', fontsize=20)\n",
    "        # ax.set_yticks([])\n",
    "        # ax.set_title(f'{term}', fontsize=10)\n",
    "        set_red(ax)\n",
    "        n+=1\n",
    "\n",
    "        fig.savefig(output_dir / f'{covariates[i]}.png')\n",
    "\n",
    "    fig, axes = plt.subplots(len(significant_nonlinears)//3, 3, figsize=(17, 5 * len(significant_nonlinears)//3))\n",
    "    if len(significant_nonlinears) > 3:\n",
    "        for row in range(len(significant_nonlinears)//3):\n",
    "            axes[row][0].set_ylabel(r'Hazard Contribution $\\Delta \\theta$', fontsize=18)\n",
    "        axes = axes.flatten()\n",
    "    else:\n",
    "        axes[0].set_ylabel(r'Hazard Contribution $\\Delta \\theta$', fontsize=18)\n",
    "    n=0\n",
    "    for act in significant_nonlinears:\n",
    "        l, i, j = act\n",
    "        if 'rnaseq' in covariates[i] and exp_name=='TCGA-GBMLGG': continue\n",
    "        inputs = ckan.spline_preacts[l][:,j,i]\n",
    "        inputs_unnorm = df_unnorm.loc[df_for_fitting.index][covariates[i]].values\n",
    "        outputs = ckan.spline_postacts[l][:,j,i]\n",
    "        rank = np.argsort(inputs)\n",
    "        inputs = inputs[rank]\n",
    "        inputs_unnorm = inputs_unnorm[rank]\n",
    "        outputs = outputs[rank]\n",
    "\n",
    "        ax = axes[n]\n",
    "        ax.scatter(inputs_unnorm, outputs, marker='x', s=60, color='red')\n",
    "        ax.plot(inputs_unnorm, outputs, color='red')\n",
    "\n",
    "        feature = format_feature(covariates[i])\n",
    "        ax.set_xlabel(feature, fontsize=20)\n",
    "        if 'CNV' in feature or 'cnv' in feature:\n",
    "            # plot vertical dotted axis line at 0\n",
    "            ax.axvline(0, color='black', linestyle='--', linewidth=2, label='No Variation')\n",
    "            ax.legend(fontsize=15)\n",
    "        # ax.set_title(f'{term}', fontsize=10)\n",
    "        set_red(ax)\n",
    "        n+=1\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(output_dir / 'significant_nonlinears_allticks.png')\n",
    "\n",
    "    for ax in axes: ax.set_yticks([])\n",
    "    fig.savefig(output_dir / 'significant_nonlinears_noyticks.png')\n",
    "\n",
    "    n=0\n",
    "    for act in significant_nonlinears:\n",
    "        l, i, j = act\n",
    "        if 'rnaseq' in covariates[i] and exp_name=='TCGA-GBMLGG': continue\n",
    "        fig.axes[n].set_xticks([])\n",
    "        n+=1\n",
    "\n",
    "    fig.savefig(output_dir / 'significant_nonlinears_noticks.png')\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if exp_name == 'TCGA-BRCA' or exp_name == 'TCGA-STAD':\n",
    "\n",
    "    formula = str(formula)\n",
    "\n",
    "    # find instances of 'group' in the formula\n",
    "    groups = []\n",
    "    for elem in formula.split(' '):\n",
    "        if 'group' in elem:\n",
    "            print(elem)\n",
    "            group_id = elem.split('_')[1]\n",
    "            groups.append(group_id)\n",
    "\n",
    "    all_groups = pickle.load(open(f'./data/TCGA/{cohort}_CNV_high_correlation_groups.pkl', 'rb'))\n",
    "\n",
    "    for group_id in groups:\n",
    "        group = all_groups[f'group_{group_id}']\n",
    "\n",
    "        # save group to txt file\n",
    "        for gene in group:\n",
    "            with open(output_dir / f'group_{group_id}.txt', 'a') as f:\n",
    "                f.write(f'{gene}\\n')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coxkan-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
